{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pubmed data is downloaded from https://www.nlm.nih.gov/databases/download/pubmed_medline.html\n",
    "\n",
    "This file is used to extract titles, abstracts, Year, and MeSH terms from the pubmed data. The data is then used to train a model to predict the MeSH terms for a given title and abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# open the file and save to a dataframe\n",
    "def parse_pubmed_xml(file_path):\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        tree = ET.parse(f)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # create a list to store the data\n",
    "        data = []\n",
    "\n",
    "        # iterate through the articles and extract the title, abstract, and journal name\n",
    "        for article in root.findall('PubmedArticle'):\n",
    "            pmid_elem = article.find('MedlineCitation/PMID')\n",
    "            pmid = pmid_elem.text if pmid_elem is not None else None\n",
    "\n",
    "            title_elem = article.find('MedlineCitation/Article/ArticleTitle')\n",
    "            title = title_elem.text if title_elem is not None else None\n",
    "\n",
    "            abstract_elem = article.find('MedlineCitation/Article/Abstract/AbstractText')\n",
    "            abstract = abstract_elem.text if abstract_elem is not None else None\n",
    "\n",
    "            year_elem = article.find('MedlineCitation/Article/Journal/JournalIssue/PubDate/Year')\n",
    "            year = year_elem.text if year_elem is not None else None\n",
    "\n",
    "            data.append([pmid, title, abstract, year])\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "30000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "# data latest version: 2021\n",
    "\n",
    "data1 = parse_pubmed_xml('data/pubmed24n1216.xml.gz')\n",
    "print(len(data1))\n",
    "\n",
    "# data2 = parse_pubmed_xml('data/pubmed24n1218.xml.gz')\n",
    "# print(len(data2))\n",
    "\n",
    "# data3 = parse_pubmed_xml('data/pubmed24n1216.xml.gz')\n",
    "# print(len(data3))\n",
    "\n",
    "data2 = parse_pubmed_xml('data/pubmed24n1084.xml.gz')\n",
    "print(len(data2))\n",
    "\n",
    "data3 = parse_pubmed_xml('data/pubmed24n1143.xml.gz')\n",
    "print(len(data3))\n",
    "\n",
    "data = data1 + data2 + data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76950\n"
     ]
    }
   ],
   "source": [
    "# remove the rows with the same pmid\n",
    "data = [list(x) for x in set(tuple(x) for x in data)]\n",
    "\n",
    "# remove the rows that have no title and abstract\n",
    "data = [x for x in data if x[1] is not None and x[2] is not None]\n",
    "\n",
    "# remove the rows that have no year\n",
    "data = [x for x in data if len(x) > 2 and x[0] is not None]\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'2023': 26794,\n",
       "         '2021': 22364,\n",
       "         '2022': 24876,\n",
       "         None: 1796,\n",
       "         '2024': 687,\n",
       "         '2020': 305,\n",
       "         '2014': 9,\n",
       "         '2019': 48,\n",
       "         '2013': 8,\n",
       "         '2017': 12,\n",
       "         '2018': 23,\n",
       "         '2003': 2,\n",
       "         '2012': 6,\n",
       "         '2002': 1,\n",
       "         '2015': 7,\n",
       "         '2016': 7,\n",
       "         '2010': 1,\n",
       "         '2009': 1,\n",
       "         '1999': 1,\n",
       "         '2011': 2})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of years\n",
    "from collections import Counter\n",
    "years = [d[3] for d in data]\n",
    "year_counts1 = Counter(years)\n",
    "year_counts1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/guolu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuations\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing abstract: French National Authority for Health assessment of metabolic surgery for type 2 diabetes remission- a meta-analysis in patients with class I to III obesity.\n",
      "Error message: list index out of range\n",
      "170098\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter data for each year\n",
    "data_2023 = [d for d in data if d[3] == '2023']\n",
    "\n",
    "\n",
    "# Extract titles and abstracts for 2023\n",
    "titles_2023 = [clean_text(d[1]) for d in data_2023]\n",
    "\n",
    "abstracts_2023 = []\n",
    "for d in data_2023:\n",
    "    if d[2] is None:\n",
    "        continue \n",
    "    try:\n",
    "        sentences = sent_tokenize(d[2])\n",
    "        sentences = [clean_text(s) for s in sentences]\n",
    "        abstracts_2023 += sentences\n",
    "    except IndexError as e:\n",
    "        print(f\"Error processing abstract: {d[1]}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "\n",
    "title_abstract_2023 = titles_2023 + abstracts_2023\n",
    "print(len(title_abstract_2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152527\n"
     ]
    }
   ],
   "source": [
    "# Filter data for each year\n",
    "data_2022 = [d for d in data if d[3] == '2022']\n",
    "\n",
    "# Extract titles and abstracts for 2022\n",
    "titles_2022 = [clean_text(d[1]) for d in data_2022]\n",
    "\n",
    "abstracts_2022 = []\n",
    "for d in data_2022:\n",
    "    if d[2] is None:\n",
    "        continue \n",
    "    try:\n",
    "        sentences = sent_tokenize(d[2])\n",
    "        sentences = [clean_text(s) for s in sentences]\n",
    "        abstracts_2022 += sentences\n",
    "    except IndexError as e:\n",
    "        print(f\"Error processing abstract: {d[1]}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "\n",
    "title_abstract_2022 = titles_2022 + abstracts_2022\n",
    "print(len(title_abstract_2022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140759\n"
     ]
    }
   ],
   "source": [
    "# Filter data for each year\n",
    "data_2021 = [d for d in data if d[3] == '2021']\n",
    "\n",
    "# Extract titles and abstracts for 2021\n",
    "titles_2021 = [clean_text(d[1]) for d in data_2021]\n",
    "\n",
    "abstracts_2021 = []\n",
    "for d in data_2021:\n",
    "    if d[2] is None:\n",
    "        continue \n",
    "    try:\n",
    "        sentences = sent_tokenize(d[2])\n",
    "        sentences = [clean_text(s) for s in sentences]\n",
    "        abstracts_2021 += sentences\n",
    "    except IndexError as e:\n",
    "        print(f\"Error processing abstract: {d[1]}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "\n",
    "title_abstract_2021 = titles_2021 + abstracts_2021\n",
    "print(len(title_abstract_2021))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the 2023 data to one json file, each line is a sentence\n",
    "with open('data/title_abstract_2023_sentences.json', 'w') as f:\n",
    "    for line in title_abstract_2023:\n",
    "        f.write(\"%s\" % line)\n",
    "\n",
    "with open('data/title_abstract_2022_sentences.json', 'w') as f:\n",
    "    for line in title_abstract_2022:\n",
    "        f.write(\"%s\" % line)\n",
    "\n",
    "with open('data/title_abstract_2021_sentences.json', 'w') as f:\n",
    "    for line in title_abstract_2021:\n",
    "        f.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a novel paradigm examining the remote induction of nocebo effects online\\n',\n",
       " 'topical atropine for childhood myopia control the atropine treatment longterm assessment study\\n',\n",
       " 'hepatocyte nuclear factor 4 a hnf4Î± a perspective in cancer\\n']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "with open('data/title_abstract_2023_sentences.json', 'r') as f:\n",
    "    title_abstract_2023_1 = f.readlines()\n",
    "\n",
    "title_abstract_2023_1[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
